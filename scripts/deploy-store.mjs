import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3'
import fs from 'fs'
import path from 'path'
import dotenv from 'dotenv'
import mime from 'mime-types'
import { fileURLToPath } from 'url'

dotenv.config()

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

// --- –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø ---
const STORE_ROOT = path.join(__dirname, '../store-data')
const DB_DIR = path.join(STORE_ROOT, 'db')
const ARCHIVES_DIR = path.join(STORE_ROOT, 'archives')
const R2_PREFIX = 'v1'

// –¢–≤–æ—è –ø—É–±–ª—ñ—á–Ω–∞ –∞–¥—Ä–µ—Å–∞ (–±–µ–∑ v1 –≤ –∫—ñ–Ω—Ü—ñ, –±–æ –º–∏ –¥–æ–¥–∞—î–º–æ —à–ª—è—Ö–∏ –¥–∏–Ω–∞–º—ñ—á–Ω–æ)
const PUBLIC_URL_BASE = 'https://pub-af821b9413f74a56ad45f675b24a2fac.r2.dev'

const s3Client = new S3Client({
  region: 'auto',
  endpoint: `https://${process.env.R2_ACCOUNT_ID}.r2.cloudflarestorage.com`,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID,
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY
  }
})

// –§—É–Ω–∫—Ü—ñ—è uploadToR2 (–∑ –≤–∏–º–∫–Ω–µ–Ω–∏–º –∫–µ—à–µ–º –¥–ª—è JSON)
async function uploadToR2(key, body, contentType) {
  let cacheControl = 'public, max-age=31536000'
  if (key.endsWith('.json')) {
    cacheControl = 'no-cache, no-store, must-revalidate, max-age=0'
  }

  try {
    const command = new PutObjectCommand({
      Bucket: process.env.R2_BUCKET_NAME,
      Key: key,
      Body: body,
      ContentType: contentType,
      CacheControl: cacheControl
    })
    await s3Client.send(command)
    console.log(`[UPLOAD] ‚úÖ ${key}`)
  } catch (err) {
    console.error(`[ERROR] ‚ùå ${key}:`, err.message)
  }
}

async function run() {
  console.log('üöÄ Starting Smart Deploy...')

  if (!fs.existsSync(DB_DIR)) {
    console.error('‚ùå Folder store-data/db not found!')
    process.exit(1)
  }

  const modFiles = fs.readdirSync(DB_DIR).filter(f => f.endsWith('.json'))
  const fullIndex = []

  // –û—Ç—Ä–∏–º—É—î–º–æ —Å–ø–∏—Å–æ–∫ –∞—Ä—Ö—ñ–≤—ñ–≤, —â–æ–± –∑–Ω–∞–π—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å
  const availableArchives = fs.existsSync(ARCHIVES_DIR) ? fs.readdirSync(ARCHIVES_DIR) : []

  console.log(`üì¶ Found ${modFiles.length} mod definitions. Processing...`)

  for (const file of modFiles) {
    const content = fs.readFileSync(path.join(DB_DIR, file), 'utf-8')
    try {
      // 1. –ß–∏—Ç–∞—î–º–æ –ª–æ–∫–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª
      const mod = JSON.parse(content)
      if (!mod.id) throw new Error('Mod missing ID')

      // --- AUTOMATIC ARCHIVE LINKING (–ú–ê–ì–Ü–Ø –¢–£–¢) ---
      // –ú–∏ —à—É–∫–∞—î–º–æ –∞—Ä—Ö—ñ–≤, —è–∫–∏–π –º–∞—î —Ç–∞–∫—É –∂ –Ω–∞–∑–≤—É, —è–∫ ID –º–æ–¥–∞, –∞–±–æ —Ç–∞–∫—É –∂ –Ω–∞–∑–≤—É, —è–∫ JSON —Ñ–∞–π–ª
      // –ù–∞–ø—Ä–∏–∫–ª–∞–¥: –¥–ª—è bmw_m5.json —à—É–∫–∞—î–º–æ bmw_m5.zip
      
      const jsonFileName = file.replace('.json', ''); // bmw_m5
      const possibleZipName = `${jsonFileName}.zip`;
      
      // –Ø–∫—â–æ –∞—Ä—Ö—ñ–≤ —ñ—Å–Ω—É—î –ª–æ–∫–∞–ª—å–Ω–æ - —Ñ–æ—Ä–º—É—î–º–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ
      if (availableArchives.includes(possibleZipName)) {
         mod.archive = `${PUBLIC_URL_BASE}/archives/${possibleZipName}`;
         console.log(`   üîó Auto-linked archive: ${possibleZipName}`);
      }
      // ----------------------------------------------

      // 2. –î–æ–¥–∞—î–º–æ –≤ –Ü–Ω–¥–µ–∫—Å (index.min.json)
      // 2. –î–æ–¥–∞—î–º–æ –≤ –Ü–Ω–¥–µ–∫—Å (index.min.json)
      fullIndex.push({
        id: mod.id,
        t: mod.title,
        a: mod.author || 'Unknown',
        c: mod.category || 'other',
        tags: mod.tags || [],
        th: mod.thumbnail,
        d: mod.uploadDate || new Date().toISOString(),
        v: mod.version || '1.0',
        ar: mod.archive || null,
        
        // !!! –î–û–î–ê–Ñ–ú–û –¶–ï–ô –†–Ø–î–û–ö !!!
        ii: mod.instructionId || null  // ii = Instruction ID
      })
      // 3. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –î–ï–¢–ê–õ–¨–ù–ò–ô –§–ê–ô–õ (mods/mod.json)
      // –ú–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –æ–±'—î–∫—Ç `mod`, —è–∫–∏–π –º–∏ —â–æ–π–Ω–æ –º–æ–¥–∏—Ñ—ñ–∫—É–≤–∞–ª–∏ (–¥–æ–¥–∞–ª–∏ mod.archive)
      await uploadToR2(
        `${R2_PREFIX}/mods/${mod.id}.json`, 
        JSON.stringify(mod), // <--- –û—Å—å —Ç—É—Ç —Ç–µ–ø–µ—Ä —î archive
        'application/json'
      )

    } catch (err) {
      console.warn(`‚ö†Ô∏è Skipped ${file}: ${err.message}`)
    }
  }

  // 4. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –Ü–Ω–¥–µ–∫—Å
  console.log(`üìä Generating index...`)
  await uploadToR2(
    `${R2_PREFIX}/index.min.json`,
    JSON.stringify(fullIndex),
    'application/json'
  )

  // 5. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó
  const instructionsPath = path.join(STORE_ROOT, 'instructions.json')
  if (fs.existsSync(instructionsPath)) {
    console.log(`üìú Uploading Instructions...`)
    await uploadToR2(`${R2_PREFIX}/instructions.json`, fs.readFileSync(instructionsPath), 'application/json')
  }

  // 6. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –ê—Ä—Ö—ñ–≤–∏
  if (fs.existsSync(ARCHIVES_DIR)) {
    console.log(`üì¶ Uploading Archives...`)
    for (const file of availableArchives) {
      if (!file.endsWith('.zip')) continue
      await uploadToR2(
        `archives/${file}`,
        fs.readFileSync(path.join(ARCHIVES_DIR, file)),
        'application/zip',
        // –ë–£–õ–û: 'public, max-age=31536000'
        // –°–¢–ê–õ–û (–¢–∏–º—á–∞—Å–æ–≤–æ):
        'no-cache, no-store, must-revalidate' 
      )
    }
  }

  console.log('üéâ Deploy Complete!')
}

run()